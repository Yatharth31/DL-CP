{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vscAAfT9EaMs"
      },
      "source": [
        "# Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FxT_lpD30Squ"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, Conv2D, ConvLSTM2D, BatchNormalization, LeakyReLU\n",
        "from PIL import Image\n",
        "import glob\n",
        "from IPython import display\n",
        "import matplotlib.animation as animation\n",
        "matplotlib.use(\"Agg\")\n",
        "import io\n",
        "import imageio\n",
        "from IPython.display import Image, display\n",
        "from ipywidgets import widgets, Layout, HBox\n",
        "from PIL import Image\n",
        "from IPython.display import HTML\n",
        "from PIL import Image, ImageDraw\n",
        "import sklearn.model_selection as sk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwlQPyp7EN1K"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive E is New Volume\n",
            " Volume Serial Number is A861-2BE5\n",
            "\n",
            " Directory of e:\\2_TY\\DL\\DL-CP\\LSTM-radar-precipitation-forecast-main\n",
            "\n",
            "23-04-2024  16:43    <DIR>          .\n",
            "23-04-2024  16:17    <DIR>          ..\n",
            "23-04-2024  13:16                49 .gitignore\n",
            "23-04-2024  17:46    <DIR>          .venv\n",
            "23-04-2024  18:35    <DIR>          data\n",
            "08-04-2024  13:48       996,176,770 data.zip\n",
            "23-04-2024  17:10             3,573 download_raw_data.py\n",
            "08-04-2024  16:30           341,951 ground_truth.gif\n",
            "23-04-2024  13:16               108 implinks.txt\n",
            "23-04-2024  16:44             5,952 lstm_model.py\n",
            "08-04-2024  16:30           135,615 model.png\n",
            "08-04-2024  19:13    <DIR>          model_saved\n",
            "08-04-2024  16:30           384,136 predicted.gif\n",
            "22-04-2024  21:56             1,770 raw_data_to_imges.py\n",
            "08-04-2024  16:30             1,198 README.md\n",
            "23-04-2024  16:50             3,903 Unet_mode.py\n",
            "08-04-2024  16:30             3,137 validation.py\n",
            "23-04-2024  18:41            59,732 weather_LSTM.ipynb\n",
            "              13 File(s)    997,117,894 bytes\n",
            "               5 Dir(s)  139,801,833,472 bytes free\n"
          ]
        }
      ],
      "source": [
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importing batch: 0\n",
            "Importing batch: 1\n",
            "Importing batch: 2\n",
            "Importing batch: 3\n",
            "Importing batch: 4\n",
            "Importing batch: 5\n",
            "Importing batch: 6\n",
            "Importing batch: 7\n",
            "Importing batch: 8\n",
            "Importing batch: 9\n",
            "Importing batch: 10\n",
            "Importing batch: 11\n",
            "Importing batch: 12\n",
            "Importing batch: 13\n",
            "Importing batch: 14\n",
            "Importing batch: 15\n",
            "Importing batch: 16\n",
            "Importing batch: 17\n",
            "Importing batch: 18\n",
            "Importing batch: 19\n",
            "Importing batch: 20\n",
            "Importing batch: 21\n",
            "Importing batch: 22\n",
            "Importing batch: 23\n",
            "Importing batch: 24\n",
            "Importing batch: 25\n",
            "Importing batch: 26\n",
            "Importing batch: 27\n",
            "Importing batch: 28\n",
            "Importing batch: 29\n",
            "Importing batch: 30\n",
            "Importing batch: 31\n",
            "Importing batch: 32\n",
            "Importing batch: 33\n",
            "Importing batch: 34\n",
            "Importing batch: 35\n",
            "Importing batch: 36\n",
            "Importing batch: 37\n",
            "Importing batch: 38\n",
            "Importing batch: 39\n",
            "Importing batch: 40\n",
            "Importing batch: 41\n",
            "Importing batch: 42\n",
            "Importing batch: 43\n",
            "Importing batch: 44\n",
            "Importing batch: 45\n",
            "Importing batch: 46\n",
            "Importing batch: 47\n",
            "Importing batch: 48\n",
            "Importing batch: 49\n",
            "Importing batch: 50\n",
            "Importing batch: 51\n",
            "Importing batch: 52\n",
            "Importing batch: 53\n",
            "Importing batch: 54\n",
            "Importing batch: 55\n",
            "Importing batch: 56\n",
            "Importing batch: 57\n",
            "Importing batch: 58\n",
            "Importing batch: 59\n",
            "Importing batch: 60\n",
            "Importing batch: 61\n",
            "Importing batch: 62\n",
            "Importing batch: 63\n",
            "Importing batch: 64\n",
            "Importing batch: 65\n",
            "Importing batch: 66\n",
            "Importing batch: 67\n",
            "Importing batch: 68\n",
            "Importing batch: 69\n",
            "Importing batch: 70\n",
            "Importing batch: 71\n",
            "Importing batch: 72\n",
            "Importing batch: 73\n",
            "Importing batch: 74\n",
            "Importing batch: 75\n",
            "Importing batch: 76\n",
            "Importing batch: 77\n",
            "Importing batch: 78\n",
            "Importing batch: 79\n",
            "Importing batch: 80\n",
            "Importing batch: 81\n",
            "Importing batch: 82\n",
            "Importing batch: 83\n",
            "Importing batch: 84\n",
            "Importing batch: 85\n",
            "Importing batch: 86\n",
            "Importing batch: 87\n",
            "Importing batch: 88\n",
            "Importing batch: 89\n",
            "Importing batch: 90\n",
            "Importing batch: 91\n",
            "Importing batch: 92\n",
            "Importing batch: 93\n",
            "Importing batch: 94\n",
            "Importing batch: 95\n",
            "Importing batch: 96\n",
            "Importing batch: 97\n",
            "Importing batch: 98\n",
            "Importing batch: 99\n",
            "Importing batch: 100\n",
            "Importing batch: 101\n",
            "Importing batch: 102\n",
            "Importing batch: 103\n",
            "Importing batch: 104\n",
            "Importing batch: 105\n",
            "Importing batch: 106\n",
            "Importing batch: 107\n",
            "Importing batch: 108\n",
            "Importing batch: 109\n",
            "Importing batch: 110\n",
            "Importing batch: 111\n",
            "Importing batch: 112\n",
            "Importing batch: 113\n",
            "Importing batch: 114\n",
            "Importing batch: 115\n",
            "Importing batch: 116\n",
            "Importing batch: 117\n",
            "Importing batch: 118\n",
            "Importing batch: 119\n",
            "Importing batch: 120\n",
            "Importing batch: 121\n",
            "Importing batch: 122\n",
            "Importing batch: 123\n",
            "Importing batch: 124\n",
            "Importing batch: 125\n",
            "Importing batch: 126\n",
            "Importing batch: 127\n",
            "Importing batch: 128\n",
            "Importing batch: 129\n",
            "Importing batch: 130\n",
            "Importing batch: 131\n",
            "Importing batch: 132\n",
            "Importing batch: 133\n",
            "Importing batch: 134\n",
            "Importing batch: 135\n",
            "Importing batch: 136\n",
            "Importing batch: 137\n",
            "Importing batch: 138\n",
            "Importing batch: 139\n",
            "Importing batch: 140\n",
            "Importing batch: 141\n",
            "Importing batch: 142\n",
            "Importing batch: 143\n",
            "Importing batch: 144\n",
            "Importing batch: 145\n",
            "Importing batch: 146\n",
            "Importing batch: 147\n",
            "Importing batch: 148\n",
            "Importing batch: 149\n",
            "Importing batch: 150\n",
            "Importing batch: 151\n",
            "Importing batch: 152\n",
            "Importing batch: 153\n",
            "Importing batch: 154\n",
            "Importing batch: 155\n",
            "Importing batch: 156\n",
            "Importing batch: 157\n",
            "Importing batch: 158\n",
            "Importing batch: 159\n",
            "Importing batch: 160\n",
            "Importing batch: 161\n",
            "Importing batch: 162\n",
            "Importing batch: 163\n",
            "Importing batch: 164\n",
            "Importing batch: 165\n",
            "Importing batch: 166\n",
            "Importing batch: 167\n",
            "Importing batch: 168\n",
            "Importing batch: 169\n",
            "Importing batch: 170\n",
            "Importing batch: 171\n",
            "Importing batch: 172\n",
            "Importing batch: 173\n",
            "Importing batch: 174\n",
            "Importing batch: 175\n",
            "Importing batch: 176\n",
            "Importing batch: 177\n",
            "Importing batch: 178\n",
            "Importing batch: 179\n",
            "Importing batch: 180\n",
            "Importing batch: 181\n",
            "Importing batch: 182\n",
            "Importing batch: 183\n",
            "Importing batch: 184\n",
            "Importing batch: 185\n",
            "Importing batch: 186\n",
            "Importing batch: 187\n",
            "Importing batch: 188\n",
            "Importing batch: 189\n",
            "Importing batch: 190\n",
            "Importing batch: 191\n",
            "Importing batch: 192\n",
            "Importing batch: 193\n",
            "Importing batch: 194\n",
            "Importing batch: 195\n",
            "Importing batch: 196\n",
            "Importing batch: 197\n",
            "Importing batch: 198\n",
            "Importing batch: 199\n",
            "Importing batch: 200\n",
            "Importing batch: 201\n",
            "Importing batch: 202\n",
            "Importing batch: 203\n",
            "Importing batch: 204\n",
            "Importing batch: 205\n",
            "Importing batch: 206\n",
            "Importing batch: 207\n",
            "Importing batch: 208\n",
            "Importing batch: 209\n",
            "Importing batch: 210\n",
            "Importing batch: 211\n",
            "Importing batch: 212\n",
            "Importing batch: 213\n",
            "Importing batch: 214\n",
            "Importing batch: 215\n",
            "Importing batch: 216\n",
            "Importing batch: 217\n",
            "Importing batch: 218\n",
            "Importing batch: 219\n",
            "Importing batch: 220\n",
            "Importing batch: 221\n",
            "Importing batch: 222\n",
            "Importing batch: 223\n",
            "Importing batch: 224\n",
            "Importing batch: 225\n",
            "Importing batch: 226\n",
            "Importing batch: 227\n",
            "Importing batch: 228\n",
            "Importing batch: 229\n",
            "Importing batch: 230\n",
            "Importing batch: 231\n",
            "Importing batch: 232\n",
            "Importing batch: 233\n",
            "Importing batch: 234\n",
            "Importing batch: 235\n",
            "Importing batch: 236\n",
            "Importing batch: 237\n",
            "Importing batch: 238\n",
            "Importing batch: 239\n",
            "Importing batch: 240\n",
            "Importing batch: 241\n",
            "Importing batch: 242\n",
            "Importing batch: 243\n",
            "Importing batch: 244\n",
            "Importing batch: 245\n",
            "Importing batch: 246\n",
            "Importing batch: 247\n",
            "Importing batch: 248\n",
            "Importing batch: 249\n",
            "Importing batch: 250\n",
            "Importing batch: 251\n",
            "Importing batch: 252\n",
            "Importing batch: 253\n",
            "Importing batch: 254\n",
            "Importing batch: 255\n",
            "Importing batch: 256\n",
            "Importing batch: 257\n",
            "Importing batch: 258\n",
            "Importing batch: 259\n",
            "Importing batch: 260\n",
            "Importing batch: 261\n",
            "Importing batch: 262\n",
            "Importing batch: 263\n",
            "Importing batch: 264\n",
            "Importing batch: 265\n",
            "Importing batch: 266\n",
            "Importing batch: 267\n",
            "Importing batch: 268\n",
            "Importing batch: 269\n",
            "Importing batch: 270\n",
            "Importing batch: 271\n",
            "Importing batch: 272\n",
            "Importing batch: 273\n",
            "Importing batch: 274\n",
            "Importing batch: 275\n",
            "Importing batch: 276\n",
            "Importing batch: 277\n",
            "Importing batch: 278\n",
            "Importing batch: 279\n",
            "Importing batch: 280\n",
            "Importing batch: 281\n",
            "Importing batch: 282\n",
            "Importing batch: 283\n",
            "Importing batch: 284\n",
            "Importing batch: 285\n",
            "Importing batch: 286\n",
            "Importing batch: 287\n",
            "Importing batch: 288\n",
            "Importing batch: 289\n",
            "Importing batch: 290\n",
            "Importing batch: 291\n",
            "Importing batch: 292\n",
            "Importing batch: 293\n",
            "Importing batch: 294\n",
            "Importing batch: 295\n",
            "Importing batch: 296\n",
            "Importing batch: 297\n",
            "Importing batch: 298\n",
            "Importing batch: 299\n",
            "Importing batch: 300\n",
            "Importing batch: 301\n",
            "Importing batch: 302\n",
            "Importing batch: 303\n",
            "Importing batch: 304\n",
            "Importing batch: 305\n",
            "Importing batch: 306\n",
            "Importing batch: 307\n",
            "Importing batch: 308\n",
            "Importing batch: 309\n",
            "Importing batch: 310\n",
            "Importing batch: 311\n",
            "Importing batch: 312\n",
            "Importing batch: 313\n",
            "Importing batch: 314\n",
            "Importing batch: 315\n",
            "Importing batch: 316\n",
            "Importing batch: 317\n",
            "Importing batch: 318\n",
            "Importing batch: 319\n",
            "Importing batch: 320\n",
            "Importing batch: 321\n",
            "Importing batch: 322\n",
            "Importing batch: 323\n",
            "Importing batch: 324\n",
            "Importing batch: 325\n",
            "Importing batch: 326\n",
            "Importing batch: 327\n",
            "Importing batch: 328\n",
            "Importing batch: 329\n",
            "Importing batch: 330\n",
            "Importing batch: 331\n",
            "Importing batch: 332\n",
            "Importing batch: 333\n",
            "Importing batch: 334\n",
            "Importing batch: 335\n",
            "Importing batch: 336\n",
            "Importing batch: 337\n",
            "Importing batch: 338\n",
            "Importing batch: 339\n",
            "Importing batch: 340\n",
            "Importing batch: 341\n",
            "Importing batch: 342\n",
            "Importing batch: 343\n",
            "Importing batch: 344\n",
            "Importing batch: 345\n",
            "Importing batch: 346\n",
            "Importing batch: 347\n",
            "Importing batch: 348\n",
            "Importing batch: 349\n",
            "Importing batch: 350\n",
            "Importing batch: 351\n",
            "Importing batch: 352\n",
            "Importing batch: 353\n",
            "Importing batch: 354\n",
            "Importing batch: 355\n",
            "Importing batch: 356\n",
            "Importing batch: 357\n",
            "Importing batch: 358\n",
            "Importing batch: 359\n",
            "Importing batch: 360\n",
            "Importing batch: 361\n",
            "Importing batch: 362\n",
            "Importing batch: 363\n",
            "Importing batch: 364\n",
            "Importing batch: 365\n",
            "Importing batch: 366\n",
            "Importing batch: 367\n",
            "Importing batch: 368\n",
            "Importing batch: 369\n",
            "Importing batch: 370\n",
            "Importing batch: 371\n",
            "Importing batch: 372\n",
            "Importing batch: 373\n",
            "Importing batch: 374\n",
            "Importing batch: 375\n",
            "Importing batch: 376\n",
            "Importing batch: 377\n",
            "Importing batch: 378\n",
            "Importing batch: 379\n",
            "Importing batch: 380\n",
            "Importing batch: 381\n",
            "Importing batch: 382\n",
            "Importing batch: 383\n",
            "Importing batch: 384\n",
            "Importing batch: 385\n",
            "Importing batch: 386\n",
            "Importing batch: 387\n",
            "Importing batch: 388\n",
            "Importing batch: 389\n",
            "Importing batch: 390\n",
            "Importing batch: 391\n",
            "Importing batch: 392\n",
            "Importing batch: 393\n",
            "Importing batch: 394\n",
            "Importing batch: 395\n",
            "Importing batch: 396\n",
            "Importing batch: 397\n",
            "Importing batch: 398\n",
            "Importing batch: 399\n",
            "Importing batch: 400\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 4.65 GiB for an array with shape (320, 18, 344, 315, 1) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m X, y \u001b[38;5;241m=\u001b[39m create_shifted_frames(dataset)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Split X and y into training and validation sets\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m \u001b[43msk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_train shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_val shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_val\u001b[38;5;241m.\u001b[39mshape)\n",
            "File \u001b[1;32mc:\\Users\\91997\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\91997\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2683\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m-> 2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2685\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[0;32m   2686\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\91997\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2685\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2681\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2684\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2685\u001b[0m         (\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m, _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2686\u001b[0m     )\n\u001b[0;32m   2687\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\91997\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:411\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
            "File \u001b[1;32mc:\\Users\\91997\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:208\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    207\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.65 GiB for an array with shape (320, 18, 344, 315, 1) and data type float64"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import h5py\n",
        "from PIL import Image\n",
        "import sklearn.model_selection as sk\n",
        "\n",
        "def create_dataset_from_raw(directory_path, resize_to):\n",
        "    resize_width = resize_to[0]\n",
        "    resize_height = resize_to[1]\n",
        "    batch_names = [os.path.join(directory_path, name) for name in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, name))]\n",
        "    dataset = np.zeros(shape=(len(batch_names), 36, resize_height, resize_width))  # (samples, filters, rows = height, cols = width)\n",
        "\n",
        "    for batch_idx, batch in enumerate(batch_names):\n",
        "        files = [x for x in os.listdir(batch) if x != '.DS_Store']\n",
        "        files.sort()\n",
        "        crn_batch = np.zeros(shape=(36, resize_height, resize_width)) \n",
        "        for idx, raster in enumerate(files):\n",
        "            fn = os.path.join(batch, raster)\n",
        "            img = h5py.File(fn)\n",
        "            original_image = np.array(img[\"image1\"][\"image_data\"]).astype(float)\n",
        "            img = Image.fromarray(original_image)\n",
        "            img = img.resize(size=(resize_width, resize_height))\n",
        "            original_image = np.array(img)\n",
        "            original_image = original_image / 255.0\n",
        "            crn_batch[idx] = original_image\n",
        "        dataset[batch_idx] = crn_batch\n",
        "        print(\"Importing batch: \" + str(batch_idx))\n",
        "    return dataset\n",
        "\n",
        "def create_shifted_frames(data):\n",
        "    x = data[:, :18, :, :]\n",
        "    y = data[:, 18:36, :, :]\n",
        "    return x, y\n",
        "\n",
        "# Specify the directory path and resize dimensions\n",
        "directory_path = './data/data/raw_training/'\n",
        "resize_to = (315, 344)\n",
        "\n",
        "# Create the dataset from raw images\n",
        "dataset = create_dataset_from_raw(directory_path, resize_to)\n",
        "\n",
        "# Expand dimensions to include channel dimension\n",
        "dataset = np.expand_dims(dataset, axis=-1)\n",
        "\n",
        "# Split dataset into input frames (X) and output frames (y)\n",
        "X, y = create_shifted_frames(dataset)\n",
        "\n",
        "# Split X and y into training and validation sets\n",
        "X_train, X_val, y_train, y_val = sk.train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksTZmPYS4kZs",
        "outputId": "73c89cd3-6bf8-4fe2-a5d0-cbfdc7b0ec9f"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import sklearn.model_selection as sk\n",
        "\n",
        "# def load_images_from_folder(folder_path, resize_to):\n",
        "#     images = []\n",
        "#     for filename in os.listdir(folder_path):\n",
        "#         img_path = os.path.join(folder_path, filename)\n",
        "#         if os.path.isfile(img_path):\n",
        "#             # Load and resize the image\n",
        "#             img = load_and_resize_image(img_path, resize_to)\n",
        "#             images.append(img)\n",
        "#     return np.array(images)\n",
        "\n",
        "# def load_and_resize_image(img_path, resize_to):\n",
        "#     # Load the image using PIL and resize it to the specified dimensions\n",
        "#     img = Image.open(img_path)\n",
        "#     img = img.resize(resize_to)\n",
        "#     # Convert the image to numpy array and normalize pixel values\n",
        "#     img = np.array(img) / 255.0\n",
        "#     return img\n",
        "\n",
        "# # Directory paths for training and testing images\n",
        "# train_folder = \"./data/images/raw_training/\"\n",
        "# test_folder = \"./data/images1/raw_validation/\"\n",
        "\n",
        "# # Resize dimensions for the images\n",
        "# resize_to = (315, 344)\n",
        "\n",
        "# # Load training and testing images\n",
        "# X_train = load_images_from_folder(train_folder, resize_to)\n",
        "# X_test = load_images_from_folder(test_folder, resize_to)\n",
        "\n",
        "# # Assuming y_train and y_test are the corresponding labels or output frames\n",
        "# # You need to adjust this part based on your data structure\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# y_train = None  # Replace None with your actual labels for training set\n",
        "# y_test = None   # Replace None with your actual labels for testing set\n",
        "\n",
        "# # Print the shapes of the training and testing sets\n",
        "# print(\"X_train shape:\", X_train.shape)\n",
        "# print(\"y_train shape:\", y_train.shape if y_train is not None else \"Not provided\")\n",
        "# print(\"X_test shape:\", X_test.shape)\n",
        "# print(\"y_test shape:\", y_test.shape if y_test is not None else \"Not provided\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpmKRug4pqW"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW_hY-vhEX9G",
        "outputId": "ca4449cb-f08f-482a-af04-b71ed0fcd205"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv_lstm2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">815,616</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_lstm2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_lstm2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_lstm2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">344</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,729</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                     │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv_lstm2d_4 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │       \u001b[38;5;34m815,616\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_lstm2d_5 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │       \u001b[38;5;34m819,456\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_lstm2d_6 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv_lstm2d_7 (\u001b[38;5;33mConvLSTM2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m344\u001b[0m, \u001b[38;5;34m315\u001b[0m,   │         \u001b[38;5;34m1,729\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m1\u001b[0m)                     │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,966,017</span> (7.50 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,966,017\u001b[0m (7.50 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,965,505</span> (7.50 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,965,505\u001b[0m (7.50 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Dense\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(ConvLSTM2D(filters=64, kernel_size=(7, 7),\n",
        "                    input_shape=(18,344,315,1),\n",
        "                    padding='same',activation=LeakyReLU(alpha=0.01), \n",
        "                    return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ConvLSTM2D(filters=64, kernel_size=(5, 5),\n",
        "                    padding='same',activation=LeakyReLU(alpha=0.01), \n",
        "                    return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3),\n",
        "                    padding='same',activation=LeakyReLU(alpha=0.01), \n",
        "                    return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ConvLSTM2D(filters=64, kernel_size=(1, 1),\n",
        "                    padding='same',activation=LeakyReLU(alpha=0.01), \n",
        "                    return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv3D(filters=1, kernel_size=(3,3,3),\n",
        "                activation='sigmoid',\n",
        "                padding='same', data_format='channels_last'))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define modifiable training hyperparameters.\n",
        "epochs = 25\n",
        "batch_size = 1\n",
        "\n",
        "#Fit the model to the training data.\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1,\n",
        ")\n",
        "model.save('./model_saved')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4896q5LxPLAR"
      },
      "source": [
        "# Predict values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "7AXGYRWNPCoG",
        "outputId": "1f129b34-8d7d-4214-8998-fcdb32cde855"
      },
      "outputs": [],
      "source": [
        "# reconstructed_model = keras.models.load_model(\"./drive/MyDrive/model_saved\")\n",
        "# pick a random index from validation dataset\n",
        "random_index = np.random.choice(range(len(X_val)), size=1)\n",
        "test_serie_X = X_val[random_index[0]]\n",
        "test_serie_Y = y_val[random_index[0]]\n",
        "\n",
        "first_frames = test_serie_X\n",
        "original_frames = test_serie_Y\n",
        "# predict the next 18 fames\n",
        "new_prediction = model.predict(np.expand_dims(first_frames, axis=0))\n",
        "new_prediction = np.squeeze(new_prediction, axis=0)\n",
        "\n",
        "fig, axes = plt.subplots(2, 18, figsize=(20, 4))\n",
        "\n",
        "# Plot the original frames.\n",
        "for idx, ax in enumerate(axes[0]):\n",
        "    ax.imshow(np.squeeze(original_frames[idx]), cmap=\"viridis\")\n",
        "    ax.set_title(f\"Frame {idx + 18}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Plot the predicted frames.\n",
        "for idx, ax in enumerate(axes[1]):\n",
        "    ax.imshow((new_prediction[idx]).reshape((344,315)), cmap=\"viridis\")\n",
        "    ax.set_title(f\"Frame {idx + 18}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Display the figure.\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H91LuZM5Wqjj"
      },
      "source": [
        "# Create animated GIFs for original frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "dWRR28xAWuGW",
        "outputId": "e8d33b91-9059-4270-9aa4-3120633f6e6f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "original_images = []\n",
        "for f in original_frames:\n",
        "    ax.set_title(f\"Ground Truth\")\n",
        "    ax.axis(\"off\")\n",
        "    crn_f = ax.imshow(np.squeeze(f),cmap='viridis', animated=False)\n",
        "    original_images.append([crn_f])\n",
        "animation_originals = animation.ArtistAnimation(fig, original_images, \n",
        "                                                interval=100, blit=False, \n",
        "                                                repeat_delay=1000)\n",
        "animation_originals.save('./drive/MyDrive/ground_truth.gif', \n",
        "                         writer=animation.PillowWriter(), dpi=100)\n",
        "HTML(animation_originals.to_html5_video())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfz35LsFwUSo"
      },
      "source": [
        "# Create animated GIF for predicted frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "JJJEGHcdwaJ7",
        "outputId": "fd9d8f93-9b1b-49db-88ce-0bf7e397a692"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "predicted_images = []\n",
        "for f in new_prediction:\n",
        "    ax.set_title(f\"Ground Truth\")\n",
        "    ax.axis(\"off\")\n",
        "    crn_f = ax.imshow(np.squeeze(f),cmap='viridis', animated=False)\n",
        "    ax.set_title(f\"Predicted frames\")\n",
        "    predicted_images.append([crn_f])\n",
        "print(len(predicted_images))\n",
        "animation_predicted = animation.ArtistAnimation(fig, predicted_images, \n",
        "                                                interval=100, blit=False, \n",
        "                                                repeat_delay=1000)\n",
        "animation_predicted.save('./drive/MyDrive/predicted.gif', \n",
        "                         writer=animation.PillowWriter(), dpi=100)\n",
        "HTML(animation_predicted.to_html5_video())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
